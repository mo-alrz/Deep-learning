{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mo-alrz/Deep-learning/blob/main/Neural%20Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-udDLHGtPDE"
      },
      "source": [
        "<a id=\"nnbasics\"></a>\n",
        "# Neural network basics\n",
        "\n",
        "<a href=\"https://www.researchgate.net/figure/Architecture-of-the-fully-connected-neural-network-The-4-machine-parameters-are-fed-into_fig2_362234527\">\n",
        "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSgGeH6qqNouAiKfdwtvnLBcOcqNY0N6Gl8B8gMLZGI9Ikbpx1SU3OjHvlRvNzJxu9BbFc&usqp=CAU\" width=200px></a>\n",
        "\n",
        "> Roadmap:\n",
        "> - **Architecture**: \"multilayer perceptrons\"\n",
        "- The need for smooth **loss** functions (instead of 0/1)\n",
        "- The **sigmoid** activation function as nonlinearity\n",
        "  - **Universal approximation theorem**\n",
        "- **Optimization** with _gradient descent_\n",
        "  - Choosing the right **step size**\n",
        "  - For deep networks: **backprogation**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \"Multilinearity\"\n",
        "\n",
        "### We were here\n",
        "<a href=\"https://www.mathworks.com/help/nnet/ug/percept_percla.gif\"><img src=\"https://drive.google.com/uc?export=view&id=1N05roQQnKMenfDGTnBbsWf9g61rBUqLk\"></a>\n",
        "\n",
        "### Our problem was\n",
        "\n",
        "<a href=\"http://drive.google.com/uc?export=view&id=1m59mOWDu7yShgMpSgw2yC8YDVzi1-fzs\"><img src=\"https://drive.google.com/uc?export=view&id=1Ci6_UtG_Lr2UnwQQv6r86382TnSfGTf5\" style=\"width: 80%;\"></a>\n"
      ],
      "metadata": {
        "id": "Op2cVLYBN2Kv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution: we need more layers!\n",
        "\n",
        "Even Minsky and Papert suggested this solution to the XOR problem\n",
        "\n",
        "<a href=\"http://slideplayer.com/slide/778829/3/images/5/Minsky+&+Papert+(1969)+offered+solution+to+XOR+problem+by.jpg\"><img src=\"https://drive.google.com/uc?export=view&id=10nkEXJlBBCV3Wj-24ywMKCaMy0TJu46e\" width=500></a>\n"
      ],
      "metadata": {
        "id": "HYg-cWSQGWJP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFFWu9XhVgc9"
      },
      "source": [
        "\n",
        "\n",
        "### How does it look in practice?\n",
        "\n",
        "<a href=\"http://scikit-learn.org/stable/_images/multilayerperceptron_network.png\"><img src=\"https://drive.google.com/uc?export=view&id=1zKuJIjW-3lcySUNB4gIJqwCETctQBhij\" width=400 ></a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Smarter learning method"
      ],
      "metadata": {
        "id": "OXZq16HBNqhr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that architecture is not enough for a usable ML model:\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1s6y_e6evZtgaR-VtmAIB0j7d8E4FFTDp\" width=600px>\n"
      ],
      "metadata": {
        "id": "5UOcPjhRHV7w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problems with the perceptron learning algorithm"
      ],
      "metadata": {
        "id": "I2s2nzEHNtc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How should we adapt the algorithm for more than one layers?\n",
        "\n",
        "It is unclear how we should compute the error and update the weights on the basis of the error -- we need an analytical method for computing the individual weights' contribution \"backward\" from the error.\n"
      ],
      "metadata": {
        "id": "1bGZfa3uNvjK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYzadGq7VgdA"
      },
      "source": [
        "\n",
        "#### We have already seen the dangerous order sensitivity + it considers only one example at a time\n",
        "In practice the perceptron update rule is quite scary:\n",
        "\n",
        "<a href=\"https://jeremykun.files.wordpress.com/2011/08/perceptron-iterations.gif\"><img src=\"https://drive.google.com/uc?export=view&id=1-WNDl_ahHQp-cbpEQa5_Jy4hK9QYY47j\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### What if the data is not linearly separable?\n",
        "We have no guarantee that the resulting weights will be optimal, i.e., that the algorithm minimizes the number of errors."
      ],
      "metadata": {
        "id": "Q7LypUiYNxvn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning as a minimization task: the need for a more appropriate loss function\n",
        "\n",
        "\n",
        "Basic intuition: we should try to **find those model parameters that minimize how \"bad\" the model is**. \"Badness\" in this context is not exclusively the error on our data set, a model can be worse than another because it's too complex, its weights are too large etc. The function to be minimized is typically called **\"loss\"** or **\"objective\" function**.\n"
      ],
      "metadata": {
        "id": "6WJSE1k7N_h1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmg4nRQ6VgdE"
      },
      "source": [
        "\n",
        "### Error rate as loss function (0/1 loss)\n",
        "\n",
        "The error rate or error number on the training data might seem to be a good loss function but, suprisingly, there is **no usable optimization algorithm for this type of loss**, even for the linear case:\n",
        "\n",
        "- The problem of finding the linear separator with the minimal error rate/number of errors is **NP-hard**, i.e., there is a polynomial time algorithm only if P=NP.  Even more surprisingly, the problem of approximating the minimum is also NP-hard $\\Rightarrow$ it is advisable to experiment with different loss functions.\n",
        "\n",
        "- One of the main problems of the error rate functions is that in certain cases **small changes in the parameters can lead to large jumps** in the function value, while in others **even large parameter values do not change the output**.\n",
        "\n",
        "<a href=\"http://fa.bianp.net/blog/images/2014/loss_01.png\"><img src=\"https://drive.google.com/uc?export=view&id=1kZHdEi-yZQEn9FM45I0uDOqSeKfstNkL\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> $\\rightarrow$ Solution: we work with **smoothed loss functions** that correlate with the error rate (e.g., being its upper limit) but which are easier to minimize.\n",
        "\n",
        "<a href=\"http://fa.bianp.net/blog/images/2014/loss_log.png\"><img src=\"https://drive.google.com/uc?export=view&id=1uoVkubaxEwZgJV779tdlOj135FSOtDt-\"></a>\n",
        "\n"
      ],
      "metadata": {
        "id": "DQIqakC3GawH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Surrogate loss functions\n",
        "\n",
        "<a href=\"http://i.imgur.com/r37lX2P.jpg\"><img src=\"https://drive.google.com/uc?export=view&id=18f0vny5HKfBa8W_6YYcqqNr1PfZJXvHm\"></a>\n",
        "\n",
        "\n",
        "It is important to note that in addition to the optimization problem, there are other important reasons for using a surrogate loss function instead of 0/1 loss: **0/1 loss is too sensitive to small perturbations**, which means that optimizing the network for it would lead to overfitting in most of the cases."
      ],
      "metadata": {
        "id": "LxDHu_QaNm_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Changing the architecture, as well: a new \"nonlinearity\"\n",
        "\n",
        "- An early idea.\n",
        "- The Perceptron's hard thresholding function: not suitable (for the same reason 0/1 loss isn't a suitable loss function).\n",
        "- Firstly the role of nonlinearity was played by the:\n",
        "\n",
        "### **Sigmoid (logistic) function**\n",
        "\n",
        "$${\\displaystyle S(x)={\\frac {1}{1+e^{-x}}}={\\frac {e^{x}}{e^{x}+1}}.}$$\n",
        "\n",
        "<a href=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/600px-Logistic-curve.svg.png\"><img src=\"https://drive.google.com/uc?export=view&id=17iKxq3jA3ZTBt5PX7HSjg6bHXQswmPam\" width=400 heighth=400></a>\n"
      ],
      "metadata": {
        "id": "muWoIdJ4JfxG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Advantages of the sigmoid as an activation function\n",
        "\n",
        "<figure class=\"image\"> <figcaption>sigmoid vs. step function</figcaption><a href=\"http://drive.google.com/uc?export=view&id=1fTTksMeUU9UTZLUDq4NF5avktkQ_p5IU\"><img src=\"https://drive.google.com/uc?export=view&id=1V3_6m8qRaD0oaddyrZfe3qf6O60P_lgm\"></a></figure>\n",
        "\n",
        "- **Differentiable** (unlike the step function used in the perceptron)\n",
        "- It is the **smoothed version of the unit step function**\n",
        "- Its range is the  $(0,1)$ interval, so **its values can be interpreted as probabilities**\n",
        "- Can produce **complex decision surfaces when used in multiple layers**\n",
        "\n",
        "<figure class=\"image\"> <figcaption>decision surfaces</figcaption>\n",
        "<a href=\"https://sebastianraschka.com/images/faq/diff-perceptron-adaline-neuralnet/8.png\"><img src=\"https://drive.google.com/uc?export=view&id=1YyoucH1nwkG48T6EiZDoZHwc1SjWgT1X\"></a></figure>\n",
        "\n",
        "(Sidenote: Adaline is a perceptron variant trained with a \"smarter learning rule\", see [here](https://sebastianraschka.com/faq/docs/diff-perceptron-adaline-neuralnet.html) )\n",
        "\n"
      ],
      "metadata": {
        "id": "BsRB_4jAJmbd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> An important advantage is that it is a **universal approximator**.\n",
        "\n",
        "<a href=\"https://i.stack.imgur.com/xcdwn.png\"><img src=\"https://drive.google.com/uc?export=view&id=1s8Kk4IztXBGTGHjWJHkyVy8DcueeL_eW\" width=500px></a>\n",
        "<a href=\"https://i.stack.imgur.com/blIBz.png\"><img src=\"https://drive.google.com/uc?export=view&id=1hxfNGUCMPo0QFPdsO0wQToTW8IoELFUh\" width=600px></a>\n",
        "<a href=\"https://ars.els-cdn.com/content/image/1-s2.0-S089360809700097X-gr3.gif\"><img src=\"https://drive.google.com/uc?export=view&id=1gz53JpAga2rjFW-MdPc3xeVTIx-v6uvo\" width=500px></a>\n"
      ],
      "metadata": {
        "id": "y6evW5nbJ4NA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRPtY0voVgdL"
      },
      "source": [
        "\n",
        "\n",
        "[Source](https://stats.stackexchange.com/questions/291492/how-can-logistic-regression-produce-curves-that-arent-traditional-functions)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG3f80dssKZJ"
      },
      "source": [
        "<a id=\"historyagain\"></a>\n",
        "### History revisited\n",
        "\n",
        "- During \"winter\" for neural models, some researchers worked - mainly in isolation - on problems regarding neural models\n",
        "- Results paved way for a later \"revolution\"\n",
        "\n",
        "- Amongst them [**George Cybenko**](https://en.wikipedia.org/wiki/George_Cybenko)\n",
        "- Proof of  \"**universal approximation theorem**\" (see below)\n",
        "- Together with the backpropagation algorithm applied by Hinton, gave new hope to research in multi layer neural networks\n",
        "\n",
        "<a href=\"https://c1.staticflickr.com/9/8568/15881996631_f9029074d5_b.jpg\"><img src=\"https://drive.google.com/uc?export=view&id=1E7U6lNg5cduF6OCr9aViszX29I0_Gh9t\" width=500></a>\n",
        "\n",
        "(After the theorem, Cybenko shifted his attention to other areas and problems of mathematics, and thus is not part of the \"deep learning movement\".)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlPLzKFJsQkN"
      },
      "source": [
        "### Universal approximation theorem (Cybenko, 1989)\n",
        "\n",
        "Let $F$ be a continuous function on a closed and bounded subset of $\\mathbb R^n$ and $\\sigma$ any sigmoid-like function, that is, $\\sigma:\\mathbb R\\rightarrow\\mathbb R$, continuous and $\\lim_{x \\to -\\infty} \\sigma(x) = 0$ and $\\lim_{x \\to \\infty} \\sigma(x) = 1$. Then for any $\\epsilon>0$ there exists a $\\hat{f}$ finite neural network with a single hidden layer whose activation function is $\\sigma$  and which is closer to $f$ than $\\epsilon$, that is,\n",
        "\n",
        "$$\\forall \\mathbf x \\in \\mathrm{Dom}(f): \\left|~f(\\mathbf x) - \\hat{f}(\\mathbf x)\\right|< \\epsilon$$\n",
        "\n",
        "Original paper: [here](https://www.dartmouth.edu/~gvc/Cybenko_MCSS.pdf). Somewhat clearer version of the original proof: [here](http://mcneela.github.io/machine_learning/2017/03/21/Universal-Approximation-Theorem.html).\n",
        "\n",
        "Illustration:\n",
        "\n",
        "<a href=\"http://drive.google.com/uc?export=view&id=1xIKYRXMchV6B6C9WmhwK0qCENbkIYGiv\"><img src=\"https://drive.google.com/uc?export=view&id=1OeKexw1HCSLxrMqubc3ruOtwnHmtXo5K\" style=\"width: 500px;\"></a>\n",
        "\n",
        "[Source](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.101.2647&rep=rep1&type=pdf)\n",
        "\n",
        "\n",
        "### Some generalizations\n",
        "\n",
        "- Hornik, 1990: The theorem also holds for continuous, bounded and not constant activation functions [here](https://web.archive.org/web/20190818232735/http://zmjones.com:80/static/statistical-learning/hornik-nn-1991.pdf)\n",
        "\n",
        "- Leshno et al, 1993: It is enough to require piecewise continuity and so called local boundedness if the function is not polynomial.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Intuitive explanation\n",
        "\n",
        "Intuitive explanation of the theorem can be found in [Chapter 4 of Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/chap4.html): it demonstrates how **function approximations can be put together from basic blocks of linear functions and sigmoid-like nonlinearities**.\n",
        "\n",
        "A very nice visual introduction can be found [here](https://towardsdatascience.com/representation-power-of-neural-networks-8e99a383586).\n",
        "\n",
        "<a href=\"https://miro.medium.com/max/536/1*WpLFxIZ9qllHlJu-_1qRuA.png\"><img src=\"https://drive.google.com/uc?export=view&id=1p5d0NROelGS47awGli5__mfs0esAM2bq\"></a>\n"
      ],
      "metadata": {
        "id": "HIUbZ6W750_4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAcrhaFzsZc1"
      },
      "source": [
        "\n",
        "If we generalize this visualization to more dimensions, we can see the compositional structure of the decision boundaries in case of deep networks, thus we can understand how they can create arbitrarily complex decision boundaries.\n",
        "<a href=\"https://miro.medium.com/max/531/1*Lf9gGY5sTEps6jvSVQR_Nw.png\"><img src=\"https://drive.google.com/uc?export=view&id=1hXYl_M3Wub5MLNDx0W04QzLHSU88HkVa\"></a>\n",
        "\n",
        "<a href=\"https://miro.medium.com/max/1017/1*xUGfnzOlmOLyIILnTSBorQ.png\"><img src=\"https://drive.google.com/uc?export=view&id=1hUyUZB8gN1LC3pRkPU4RwPNvonJ0UDex\"></a>\n",
        "\n",
        "This image might be familiar from the ensemble methods, but the self learning and hierarchical nature is quite new!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The solution for an optimization algorithm? -- Gradient descent\n",
        "<a href=\"https://sebastianraschka.com/images/blog/2015/singlelayer_neural_networks_files/perceptron_animation.gif\"><img src=\"https://drive.google.com/uc?export=view&id=1IVQBJxq8tf0vsMWw9vVI_PutXJ0J5aL3\"></a>\n",
        "\n",
        "The Gradient Descent algorithm takes a small step in right direction taking into consideration all examples of the training data, so it moves toward the minimum in the error space.\n"
      ],
      "metadata": {
        "id": "XhGaJ2zgHJ4Q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GRegsIRVgdJ"
      },
      "source": [
        "### Gradient Descent algorithm\n",
        "If the function to be minimized is the **differentiable** $F:\\mathbb R^n\\rightarrow \\mathbb R$,  and **$\\eta _n$ is a series of learning rates** and  $K$ is the number of steps then the algorithm is\n",
        "\n",
        "1. $\\mathbf p_0 :=  \\mathbf p_{\\mathrm init}$ (**initial parameters**  [for neural nets these are the weights and biases]):\n",
        "2. for k $\\in [1..K]$:\n",
        "    - $\\mathbf g_k :=\\nabla F(\\mathbf p_{k-1})$ (compute the value of the **derivative of the loss function for the actual parameters**)            \n",
        "    - $\\mathbf p_k := \\mathbf p_{k-1} - \\eta_k \\mathbf g_k$ (**take a step in the direction opposite to the gradient**)\n",
        "3. The result is $\\mathbf p_K$.\n",
        "\n",
        "<a href=\"https://sebastianraschka.com/images/blog/2015/singlelayer_neural_networks_files/perceptron_gradient_descent_1.png\"><img src=\"https://drive.google.com/uc?export=view&id=16Ejy98onOnUqHZ6PbuK8Ewp_6_b7PwP6\"></a>\n",
        "\n",
        "### Convergence\n",
        "\n",
        "Under certain conditions (among others, $F$ has to be convex)  the series generated by the algorithm is guaranteed to converge to the minimum: the $\\eta_n$ series can be chosen to be a constant series such that the convergence rate is $\\mathcal O(1/k)$, that is,  if $F$ reaches its minimum at $\\mathbf p^*$ then there is an $\\alpha$ constant for which for any $k$, $F(\\mathbf{p}_k)-F(\\mathbf{p}^*)\\leq \\frac{\\alpha}{k}$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Too small and too large learning rates\n",
        "\n",
        "<a href=\"https://cdn-images-1.medium.com/max/1600/1*EP8stDFdu_OxZFGimCZRtQ.jpeg\"><img src=\"https://drive.google.com/uc?export=view&id=1e0NZxneJuJyT6CRVDW7gmjZ7sLzpDW28\" width=\"600\"></a>\n",
        "\n"
      ],
      "metadata": {
        "id": "pdmNBpQaNhqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=download&id=1p3fEmYKIhaiK5ShIyWTA7wMznOucFGNF\" align=\"right\" width=500px>\n",
        "\n",
        "##### Example on the _tensorflow playground_\n",
        "\n",
        "For a particular classification task with a particular network...\n",
        "\n",
        "* [Training with a small learning rate...](https://playground.tensorflow.org/#activation=sigmoid&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.63438&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)\n",
        "  - ~500 epoch training time\n",
        "* [Training with just the right learning rate...](https://playground.tensorflow.org/#activation=sigmoid&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.3&regularizationRate=0&noise=0&networkShape=4,2&seed=0.63438&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)\n",
        "  - ~100 epoch training time\n",
        "* [Training with too big a learning rate...](https://playground.tensorflow.org/#activation=sigmoid&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=10&regularizationRate=0&noise=0&networkShape=4,2&seed=0.63438&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)\n",
        "  - no convergence"
      ],
      "metadata": {
        "id": "OImAGLRC41K-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlSfbVXQ0Dqy"
      },
      "source": [
        "### Moving from the parameter space to the \"error space\"\n",
        "\n",
        "The change of the decision boundary corresponds to decreasing the error.\n",
        "<figure class=\"image\"><figcaption>Error as a function of parameter(s)</figcaption><a href=\"https://iamtrask.github.io/img/sgd_optimal.png\"><img src=\"https://drive.google.com/uc?export=view&id=1Yq73R3HMAz2afnw1TUcH4w0M15MKLYo2\" width=700px></a></figure>\n",
        "\n",
        "<figure class=\"image\"><figcaption>Space defined by input variables</figcaption>\n",
        "<a href=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/06/23104835/Qc281.jpg\"><img src=\"https://drive.google.com/uc?export=view&id=1C5VsVjrzBmBMtLZjot4eo02ChUu0Q6qH\"></a></figure>\n",
        "\n",
        "**Notice that if the separation is nonlinear then curvature of the decision boundary/surface increases. Somewhat simplifying the matter we can assume that the weight vector's values are increasing and the decision surface can be described by a higher order polynomial.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For deep architectures: Backpropagation\n"
      ],
      "metadata": {
        "id": "gTPUn210NGNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameter optimization with Gradient Descent"
      ],
      "metadata": {
        "id": "jWMX1BKAJ_nV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameter optimization with Gradient Descent requires at every step of the process the calculation of\n",
        "+ The **loss**: value of  $L$ loss function on the training data set $D=\\{d_1,\\dots,d_N\\}$ with actual parameters $\\theta$: $$L_D(\\theta)$$\n",
        "+ The **gradient of the loss** with respect to a change for the actual parameters:\n",
        "$$\\frac{\\partial L_D(\\theta)}{\\partial \\theta}.$$\n",
        "\n",
        "Since the loss is typically the **average of losses on the examples** of the dataset, both calculation tasks can be reformulated in terms of the loss and gradient on individual examples:\n",
        "\n",
        "$$L_D(\\theta) = \\frac{1}{N}\\sum_d L_d(\\theta)$$\n",
        "\n",
        " $$\\frac{\\partial L_D(\\theta)}{\\partial \\theta}=\\frac{1}{N}\\sum_d\\frac{\\partial L_d(\\theta)}{\\partial \\theta}$$\n",
        "\n",
        "Note: the derivation task is NOT symbolic: we are not interested in derivative of $L$ in general (e.g. as a symbolic formula) but **only its numerical value for the actual parameters**.\n",
        "\n",
        "Key for the solution is that we can build a circuit-like **computational graph** for the loss:\n",
        "- **Parameters and training data** are inputs entering at the leaves\n",
        "- Nodes are simple(r) **mathematical operations** that act as gates transforming their numeric inputs to outputs\n",
        "- Mathematical operations in question typically (at least piecemeal) **differentiable** functions of inputs\n"
      ],
      "metadata": {
        "id": "HEh_IWoFJ8fu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YefYAxWRsguk"
      },
      "source": [
        "\n",
        "### A toy example\n",
        "\n",
        "Regression task with training data  $\\langle  x_1,y_1\\rangle, \\dots,\\langle x_N,y_N\\rangle$ using the \"network\"\n",
        "\n",
        "<a href=\"http://drive.google.com/uc?export=view&id=1xbYaI7j7AcBFvOyI80XJAlWmkeuxOCfH\"><img src=\"https://drive.google.com/uc?export=view&id=13tf4kpvfugbotPbpz-TEqN7h4ltehuRM\" width=\"150\"></a>\n",
        "\n",
        "which computes\n",
        "\n",
        "$$\\hat{y} = w\\cdot x  + b$$\n",
        "\n",
        "as a prediction for an $x$ input. Using squared loss, loss for a single $d=\\langle x, y\\rangle$ example:\n",
        "\n",
        "$$L_d(\\langle w, b \\rangle) = (\\hat y -y)^2 = (wx + b - y)^2\n",
        "$$\n",
        "corresponding **computational graph** can be\n",
        "\n",
        "<a href=\"http://drive.google.com/uc?export=view&id=1517qyzShAbQ5flRIVXErIxmwI1GFwmDS\"><img src=\"https://drive.google.com/uc?export=view&id=1WtXYNEB2POwCf1H-gKE3c_S3pjFAz6dK\" width=\"500\"></a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Forward pass\n",
        "\n",
        "Assume current parameter values are $w = 3$ and $b = 2$, and the current example is $x = 4, y = 5$. To calculate loss on this training example, have to calculate final output of graph by calculating output of all internal operation nodes/gates as values flow from left to right:\n",
        "\n",
        "<a href=\"http://drive.google.com/uc?export=view&id=1YRkPfxLl8vkaKANFz0yoxhv-jmY2fPrD\"><img src=\"https://drive.google.com/uc?export=view&id=14L2R6GqPme-P2gJbvPTedGkKZz-4c4xq\" width=\"500px\"></a>"
      ],
      "metadata": {
        "id": "4HWYOcbENJki"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtA621j9srRc",
        "outputId": "1626b5b0-c9d8-4bd1-b68c-7a79a10e45cc"
      },
      "source": [
        "x = 4; y = 5; w = 3; b = 2\n",
        "\n",
        "prod = x * w\n",
        "y_hat  = prod + b\n",
        "error = y_hat - y\n",
        "loss = error ** 2\n",
        "\n",
        "print(f\"The loss for w={w}, b={b}, x={x} and y={y} is {loss}.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The loss for w=3, b=2, x=4 and y=5 is 81.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And that is all for the __forward pass__ on our computational graph."
      ],
      "metadata": {
        "id": "FNu7q0jO8Y8t"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU3AskVysxY8"
      },
      "source": [
        "\n",
        "\n",
        "### Backpropagation\n",
        "\n",
        "Having calculated the value of the loss function for the current example, our next task is to compute the gradient of the parameters:\n",
        "\n",
        "$$\\frac{\\partial L_d(\\theta)}{\\partial \\theta}= \\left\\langle \\frac{\\partial L_d(w)}{\\partial w}, \\frac{\\partial L_d(b)}{\\partial b}\\right\\rangle\n",
        "$$\n",
        "\n",
        "for which we have to calculate the partial derivative of the loss with respect to $w$ and $b$. Somewhat surprisingly, in this case we can **work backwards, from right to left** by computing partial derivatives with respect to the operation outputs until we reach the partial derivatives of $L$ we are interested in, with respect to $w$ and $b$. (This is the so called \"backpropagation of error\" [although \"backpropagation of loss\" would be more precise on our case]).\n",
        "\n",
        "The mathematical ground for doing so is the **chain rule** for derivatives, according to which\n",
        "\n",
        "$$\n",
        "\\frac{\\partial F}{\\partial \\alpha} = \\frac{\\partial F}{\\partial \\beta} \\cdot \\frac{\\partial \\beta}{\\partial \\alpha}\n",
        "$$\n",
        "which, for our purposes, means that we can calculate the derivative of the loss with respect to any value $\\alpha$ in the computational graph which is the input of an $f$ operation with the $\\beta$ output simply as\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial \\alpha} = \\frac{\\partial L}{\\partial \\beta} \\cdot \\frac{\\partial \\beta}{\\partial \\alpha} =\n",
        "\\frac{\\partial L}{\\partial \\beta} \\cdot \\frac{\\partial f(\\alpha)}{\\partial \\alpha}\n",
        "$$\n",
        "\n",
        "To do that, we need to know **the derivative of the operations in the graph**, which are, fortunately, very simple:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial x^2}{\\partial x} = 2x\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{\\partial (x - y)}{\\partial x} = 1, \\frac{\\partial (x - y)}{\\partial y} = -1\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{\\partial (x + y)}{\\partial x} = 1, \\frac{\\partial (x + y)}{\\partial y} = 1\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{\\partial (x \\cdot y)}{\\partial x} = y, \\frac{\\partial (x \\cdot y)}{\\partial y} = x\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Using these derivatives and applying the chain rule step by step the loss derivatives can be calculated as\n",
        "\n",
        "<a href=\"http://drive.google.com/uc?export=view&id=1johrny_RNeV14iatNruZ0h_jXhb6kCyj\"><img src=\"https://drive.google.com/uc?export=view&id=1DQA9Y9rVkJEh2EdqKzaBwTazf4fNtg_n\" width=\"500px\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIb7RKV8s6GI",
        "outputId": "e172c450-f47b-4edf-c01a-aa34e1ae9e0b"
      },
      "source": [
        "def backward_pass(loss):\n",
        "  '''Perform backward pass in toy example: propagate the error back,\n",
        "  finding the gradients for w and b.'''\n",
        "  x = 4\n",
        "  y = 5\n",
        "\n",
        "  error = loss**(1/2)\n",
        "\n",
        "  d_error = 2 * error # for the first operation node we can directly calculate the derivative\n",
        "\n",
        "  ## then use the chain rule all throughout:\n",
        "\n",
        "  d_y_hat = d_error * 1\n",
        "\n",
        "  d_b = d_y_hat * 1\n",
        "\n",
        "  d_prod = d_y_hat * 1\n",
        "\n",
        "  d_w = d_prod * x\n",
        "\n",
        "  print(f\"d_w is {round(d_w, 4)}\")\n",
        "  print(f\"d_b is {round(d_b, 4)}\")\n",
        "\n",
        "  return d_w, d_b\n",
        "\n",
        "d_w, d_b = backward_pass(loss=81)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d_w is 72.0\n",
            "d_b is 18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5VEssxds3XD"
      },
      "source": [
        "### Update on the basis of this single data point\n",
        "\n",
        "- As our current $\\langle w, b\\rangle$ parameter vector is $\\langle 3, 2 \\rangle$ and,\n",
        "- according to our calculation, the gradient for this data point is $\\langle \\frac{\\delta L}{\\delta w}, \\frac{\\delta L}{\\delta b} \\rangle = \\langle 72, 18\\rangle$,\n",
        "- then with a **learning rate** of $\\frac{1}{18}$ (for simplicity),\n",
        "- our updated parameter vector for this single data point would be $\\langle 3 - \\frac{1}{18}\\cdot 72, 2 - \\frac{1}{18}\\cdot 18\\rangle$ = $\\langle -1, 1\\rangle$,\n",
        "- for which the loss on this example is 64, which is indeed less then the previous 81 loss value.\n",
        "\n",
        "__Of course, in reality we typically make updates on the basis of more than one data point!__ (More about this later.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def do_update(w, b, d_w, d_b, learning_rate):\n",
        "  '''Update w and b in the toy example based on the gradients d_w, d_b and the learning_rate.'''\n",
        "  updated_params =  (w - learning_rate*d_w, b - learning_rate * d_b)\n",
        "  print(\"The updated parameters:\", \"w =\", round(updated_params[0], 4), \"; b =\", round(updated_params[1], 4))\n",
        "  return updated_params\n",
        "\n",
        "def forward_pass(w, b):\n",
        "  '''Do the forward pass in the toy example, calculating the loss given the parameters w and b'''\n",
        "  x = 4\n",
        "  y = 5\n",
        "  return (x * w + b - y) ** 2\n",
        "\n",
        "w, b = 3, 2\n",
        "for i in range(1, 7):\n",
        "  print(\"--- Update nr.\", i)\n",
        "  print(\"before update:\", \"w =\", round(w, 4), \", b =\", round(b, 4))\n",
        "\n",
        "  ## do forward pass, get loss\n",
        "  loss = forward_pass(w, b)\n",
        "\n",
        "  ## do backward pass, get gradient\n",
        "  d_w, d_b = backward_pass(loss )\n",
        "\n",
        "  ## we don't want to overshoot our mark --- see above, so we should make sure the learning rate is of a reasonable magnitude;\n",
        "  ## here with a brute force solution, we will learn about refined methods for this!\n",
        "  ## Task: check what would happen if we didn't control the learning rate.\n",
        "  lr_dampening_factor = 10**(-int(np.log10(d_w)) )\n",
        "  learning_rate = (1/18) * lr_dampening_factor\n",
        "  print(f\"Updating with learning rate {learning_rate:.2E}...\")\n",
        "\n",
        "  ## do update to parameters (w and b)\n",
        "  w, b = do_update(w = w, b = b, d_w=d_w, d_b=d_b, learning_rate = learning_rate )\n",
        "\n",
        "  ## calculate the new loss\n",
        "  new_loss = forward_pass(w, b)\n",
        "  print(\"The loss with the new parameters is:\", round(new_loss, 4))\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n09dsWgI9LnG",
        "outputId": "70c43505-7e95-4346-d881-0afc379ad950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Update nr. 1\n",
            "before update: w = 3 , b = 2\n",
            "d_w is 72.0\n",
            "d_b is 18.0\n",
            "Updating with learning rate 5.56E-03...\n",
            "The updated parameters: w = 2.6 ; b = 1.9\n",
            "The loss with the new parameters is: 53.29\n",
            "\n",
            "--- Update nr. 2\n",
            "before update: w = 2.6 , b = 1.9\n",
            "d_w is 58.4\n",
            "d_b is 14.6\n",
            "Updating with learning rate 5.56E-03...\n",
            "The updated parameters: w = 2.2756 ; b = 1.8189\n",
            "The loss with the new parameters is: 35.0596\n",
            "\n",
            "--- Update nr. 3\n",
            "before update: w = 2.2756 , b = 1.8189\n",
            "d_w is 47.3689\n",
            "d_b is 11.8422\n",
            "Updating with learning rate 5.56E-03...\n",
            "The updated parameters: w = 2.0124 ; b = 1.7531\n",
            "The loss with the new parameters is: 23.0657\n",
            "\n",
            "--- Update nr. 4\n",
            "before update: w = 2.0124 , b = 1.7531\n",
            "d_w is 38.4214\n",
            "d_b is 9.6054\n",
            "Updating with learning rate 5.56E-03...\n",
            "The updated parameters: w = 1.7989 ; b = 1.6997\n",
            "The loss with the new parameters is: 15.175\n",
            "\n",
            "--- Update nr. 5\n",
            "before update: w = 1.7989 , b = 1.6997\n",
            "d_w is 31.1641\n",
            "d_b is 7.791\n",
            "Updating with learning rate 5.56E-03...\n",
            "The updated parameters: w = 1.6258 ; b = 1.6565\n",
            "The loss with the new parameters is: 9.9836\n",
            "\n",
            "--- Update nr. 6\n",
            "before update: w = 1.6258 , b = 1.6565\n",
            "d_w is 25.2775\n",
            "d_b is 6.3194\n",
            "Updating with learning rate 5.56E-03...\n",
            "The updated parameters: w = 1.4854 ; b = 1.6213\n",
            "The loss with the new parameters is: 6.5682\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOBGSEn_tFxE"
      },
      "source": [
        "### Generalization\n",
        "- Method of computing loss and its gradient with recursive forward pass and backpropagation on a computational graph with simpler differentiable operations as nodes can be used to efficiently implement Gradient Descent for feed-forward neural networks in general.\n",
        "- All modern neural network frameworks use variants of this approach to implement gradient decent.\n",
        "- Important difference to our toy example is that \"real life\" computational graphs for neural networks mostly contain operations with higher dimensional (vector/matrix/tensor) arguments\n",
        "- Frameworks have to provide efficient implementations of the derivatives of these operations, e.g., that of matrix multiplication.\n",
        "\n",
        "Simple example of a __vectorized__ computational graph, consider the following network with a hidden layer:\n",
        "\n",
        "<a href=\"http://drive.google.com/uc?export=view&id=1F4TOpCCuRKh8Bvh7FJRKEXq7Ex-OS2Nr\"><img src=\"https://drive.google.com/uc?export=view&id=1K-Urkrl53Mznto7kiB8ojzU2hR-jt8l5\" width=\"350px\"></a>\n",
        "\n",
        "\n",
        "Mathematically, if the hidden layer's weights are $\\mathbf W = \\begin{bmatrix} w_{11} & w_{12} & w_{13} \\\\ w_{21} & w_{22} & w_{23}\\end{bmatrix}$, its biases are  $\\mathbf {b}^h = \\begin{bmatrix}b^h_1 \\\\ b^h_2 \\end{bmatrix}$, the output layer's weights are $\\mathbf v =\\begin{bmatrix}v_1 & v_2\\end{bmatrix}$ and its bias is $b$ then the network's output for an $\\mathbf x = \\begin{bmatrix}x_1 \\\\ x_2 \\\\ x_3\\end{bmatrix}$ input is\n",
        "\n",
        "$$ \\hat y = \\begin{bmatrix}v_1 & v_2\\end{bmatrix}\\cdot \\sigma \\left ( \\begin{bmatrix} w_{11} & w_{12} & w_{13} \\\\ w_{21} & w_{22} & w_{23}\\end{bmatrix} \\cdot \\begin{bmatrix}x_1 \\\\ x_2 \\\\ x_3\\end{bmatrix} + \\begin{bmatrix}b^h_1 \\\\ b^h_2 \\end{bmatrix}\\right ) + b = \\mathbf v \\cdot \\sigma(\\mathbf W\\cdot \\mathbf x  + \\mathbf {b}^h) + b $$\n",
        "\n",
        "Accordingly, the corresponding computational graph in terms of matrices and vectors is along the lines of\n",
        "\n",
        "<a href=\"http://drive.google.com/uc?export=view&id=1HO9C0srDTZTT6ZYAQmCRhLj89yFwd03d\"><img src=\"https://drive.google.com/uc?export=view&id=1aXG2XhMFOtolJVjxBRmUpW_SIiGuDH_N\" width=\"500px\"></a>\n"
      ]
    }
  ]
}