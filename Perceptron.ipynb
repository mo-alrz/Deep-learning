{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mo-alrz/Deep-learning/blob/main/Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# History of neural machine learning: overview\n",
        "\n",
        "The approximate history of neural machine learning can be outlined as follows:\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1lJC66UW0YvaTNM8ZRqs86ntAQid6Y8Ar\" width=100%>"
      ],
      "metadata": {
        "id": "i5-Y6lRtC8ci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Artificial neurons\n",
        "\n",
        "<a href=\"https://commons.wikimedia.org/wiki/File:Artificialneuronhjdevias.jpeg\">\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Artificialneuronhjdevias.jpeg/776px-Artificialneuronhjdevias.jpeg\" width=400px></a>\n",
        "\n",
        ">Roadmap:\n",
        ">- Biological inspirations\n",
        "- Rosenblatt's Perceptron model\n",
        "  - single neuron\n",
        "  - classifier\n",
        "- Perceptron Architecture\n",
        "  - linear\n",
        "  - thresholding\n",
        "- Perceptron Learning rule\n",
        "  - Loss used: 0/1\n",
        "  - some important notions: epoch, learning rate\n",
        "- Limitations of Perceptrons: XOR problem\n",
        "- History of AI as a series of summers and winters"
      ],
      "metadata": {
        "id": "VZVRdhXKjdFw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JV7Q61JGtPC2"
      },
      "source": [
        "<a id=\"demo\"></a>\n",
        "# Starting with a single neuron: the Perceptron model\n",
        "\n",
        "Perceptrons are just another model in [Scikit](http://scikit-learn.org/stable/modules/neural_networks_supervised.html), isn't it?\n",
        "\n",
        "<a href=\"http://scikit-learn.org/stable/_images/sphx_glr_plot_mlp_alpha_0011.png\"><img src=\"https://drive.google.com/uc?export=view&id=19crcivUVK83eyGEgKWo9qB7MFH8YiCah\" width=400 heigth=400></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W78azNgBVfU",
        "outputId": "4e98a70f-58e2-473e-e0e6-52a6fbbc622c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore') #For presentation purposes\n",
        "\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "X = [[0., 0.],\n",
        "     [1., 1.]]\n",
        "\n",
        "y = [0,\n",
        "     1]\n",
        "\n",
        "clf = Perceptron(random_state=1)\n",
        "\n",
        "clf.fit(X, y)\n",
        "\n",
        "new_input=[[2., 2.],\n",
        "           [-1., -2.]]\n",
        "\n",
        "pred = clf.predict(new_input)\n",
        "\n",
        "print(\"Predictions:\", pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "all_inputs = X + new_input\n",
        "all_outs = list(y) + list(pred)\n",
        "sns.scatterplot(x=[x[0] for x in all_inputs],\n",
        "                y=[x[1] for x in all_inputs],\n",
        "                hue = all_outs,\n",
        "                style=[\"TRAIN\" for _ in range(len(X))] + [\"TEST\" for _ in range(len(new_input))],\n",
        "                s=100)\n",
        "plt.xlabel(\"var1\")\n",
        "plt.ylabel(\"var2\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pKm-dJMH6UPh",
        "outputId": "6389d431-47c8-4117-9a0f-f259ab10de12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"But _no_ predict proba --- we will see why!\")\n",
        "try:\n",
        "  clf.predict_proba(new_input)\n",
        "except Exception as e:\n",
        "  print(type(e).__name__, \"---\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oi_Xf46PEcJ8",
        "outputId": "2517b7f8-0993-4977-89c7-8037452bf4e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "But _no_ predict proba --- we will see why!\n",
            "AttributeError --- 'Perceptron' object has no attribute 'predict_proba'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Necessary constituents of training a model\n",
        "\n",
        "<img src=\"http://drive.google.com/uc?export=view&id=1s6y_e6evZtgaR-VtmAIB0j7d8E4FFTDp\" width=600px>\n",
        "\n",
        "For a machine learning model to work, we need all of these three components, and they have to work in tandem. Please bear this is mind during our analysis of the perceptron and neural network models, since we will be demonstrating solutions / innovations for one or the other elements at a time, but they all have repercussions for the other elements."
      ],
      "metadata": {
        "id": "x4K66AmsN8zH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perceptron model\n",
        "\n",
        "## \"The Psychologists\"\n",
        "\n",
        "- Original motivation of earliest neural model of a single neuron: from \"electronic\" modeling of perception\n",
        "  - First mathematical model of neuron (1943) by Warren McCulloch (neuroscientist) and Walter Pitts (logician)\n",
        "- Influence of Psychology still visible in AI: visual processing, acoustic processing, natural language processing\n",
        "\n",
        "### The Hero:\n",
        "\n",
        "The psychologist Frank Rosenblatt and the Mark I perceptron:\n",
        "\n",
        "<a href=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRozuUtQVt1EyFVVfovXp5tC9iP3f5mM7tMy3jAlVaarA7gf_zE\"><img src=\"https://drive.google.com/uc?export=view&id=1py-fIFQIj1Hp9sutMJWFoiyxU-3JJUBy\" width=600 heigth=600></a>\n",
        "\n",
        "\n",
        "### The hardware:\n",
        "<a href=\"https://s3.amazonaws.com/s3.timetoast.com/public/uploads/photos/7146113/Mark-I.jpeg?1477813660\"><img src=\"https://drive.google.com/uc?export=view&id=13uW_M5ouDSCtptLXqF92OzsoSAvqfGEo\" width=600 heigth=600></a>\n",
        "\n",
        "- Original perceptron models and their update mechanisms not aimed at digital computers but specialized analog hardware!\n",
        "\n",
        "(Hardware innovation - though not analog, but specialized - is kicking in again, see [here](https://www.engineering.com/Hardware/ArticleID/16753/The-Great-Debate-of-AI-Architecture.aspx).)\n",
        "\n"
      ],
      "metadata": {
        "id": "W7EvO08tjKxQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### The learning algorithm:\n",
        "<a href=\"http://www.rutherfordjournal.org/images/TAHC_perceptron.jpg\"><img src=\"https://drive.google.com/uc?export=view&id=1K7BFvi9OCytrCYcNakp8PycEb7cVla-A\" width=600 heigth=600></a>\n",
        "\n",
        "- Weights of the perceptron are set with variable rotary resistors.\n",
        "\n",
        "Inspiration of \"learning rules\" from [\"**Hebbian learning**\"](https://en.wikipedia.org/wiki/Hebbian_theory):\n",
        "- Neural learning relying on **local information** only.\n",
        "- Correlation patters of neuron firing strengthen the synaptic connections\n",
        "  - Colloquially: \"**What fires together, wires together**\"\n",
        "- Rather vague learning rule not applicable in practice\n",
        "- Rather limited solutions until advent of backpropagation\n",
        "\n",
        "(Sidenote: Backpropagation is also extreme, since it relies too heavily on a distant supervision signal - so there is maybe a way to have a \"semi-hebbian\" learning procedure - see \"synthetic gradients\".)\n"
      ],
      "metadata": {
        "id": "bPRQlR9OjNB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Biological motivation\n",
        "\n",
        "### Mathematical representation of a neuron's soma\n",
        "\n",
        "<a href=\"http://drive.google.com/uc?export=view&id=1tedMjIowYM8Y68C8fRrZJ2JRsFRQx1P5\"><img src=\"https://drive.google.com/uc?export=view&id=1nF5EfVhgia0Zzpm5woRlBJ-KXSthV9e9\"></a>\n"
      ],
      "metadata": {
        "id": "yxlNyvSu2ZsV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Thresholding\n",
        "\n",
        "- Neurons do not \"fire\" continuously\n",
        "- Their activation has to be modeled with some kind of a step function\n",
        "\n",
        "<a href=\"http://www.saedsayad.com/images/ANN_Unit_step.png\"><img src=\"https://drive.google.com/uc?export=view&id=1XDNopwwsVTCLnC4ioN8tv1xbfLYlF9-e\"></a>\n",
        "\n",
        "Simplest \"nonlinearity\" - later we will encounter a plethora of others"
      ],
      "metadata": {
        "id": "D0jthIv12el2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perceptron: Linear Threshold Unit\n",
        "\n",
        "<a href=\"http://slideplayer.com/slide/5214241/16/images/5/Perceptron:+Linear+threshold+unit.jpg\"><img src=\"https://drive.google.com/uc?export=view&id=1Da8YDVCuy4wDyrLTBEcCySn8qBdOs3Yx\" width=600px></a>\n",
        "\n",
        "**Input layer**\n",
        "\n",
        "- $x_{1..n}$ are the input values, \"input activations\"\n",
        "- $x_{0}$ is also present! -- This is the  \"bias unit\", or \"bias term\""
      ],
      "metadata": {
        "id": "sUzqJEd92pe1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP_GF8KUtPC6"
      },
      "source": [
        "\n",
        "### \"Biological inspiration\"\n",
        "\n",
        "\n",
        "<a href=\"http://drive.google.com/uc?export=view&id=1D75C1LThbDYqs4gYUz5kC8cZJprQHBPB\"><img src=\"https://drive.google.com/uc?export=view&id=1EQa7ODziQoOVoLi1nZZ2yyJfOxBgrqr8\" width=55%></a>\n",
        "\n",
        "\n",
        "[source](https://www.facebook.com/photo.php?fbid=2063218160389423&set=gm.2075284019202050&type=3&theater)\n",
        "\n",
        "## Capable of modeling logical operations\n",
        "- Logic considered pinnacle of cognitive activities\n",
        "- \"It can learn, it models logic, what else would be needed?\"\n",
        "- Perceptron's problems with modeling certain logical functions had huge effect in history of AI.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##  Artificial neuron -- mathematical model\n",
        "\n",
        "(the mathematical discussion follows mainly that of [Hal Daum√© III](http://ciml.info/dl/v0_99/ciml-v0_99-ch04.pdf))\n"
      ],
      "metadata": {
        "id": "nRaCR7De2w3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Activation function\n",
        "\n",
        "with\n",
        "- $\\mathbf x = \\langle x_1,...,x_D \\rangle $ incoming activations,\n",
        "- $\\mathbf w = \\langle w_1,...,w_D \\rangle$ weights, and\n",
        "- $b$ bias\n",
        "\n",
        "the outgoing activation is\n",
        "\n",
        "$a(x_1,...,x_D) = \\sum_{d=1}^D w_d x_d +b$ where\n",
        "\n",
        "If $a(\\mathbf{x}) \\geq 0$ then the input is classified as a positive if $a(\\mathbf{x}) < 0$ then as a negative instance.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9dbMQ7-n2xxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<a href=\"https://raw.githubusercontent.com/qingkaikong/blog/master/39_ANN_part2_step_by_step/figures/figure1_perceptron_structure.jpg\"><img src=\"https://drive.google.com/uc?export=view&id=1fGwrmYGp8D6mwI1ZgbVb5R33IqLS1P2z\"></a>\n",
        "\n",
        "\n",
        "> \"Bias term\" here shouldn't be confused with concept of \"bias\" as it comes up in the discussion of overfitting, although the semantics is similar: a general \"prejudice\" which influences the behavior of the system.\n"
      ],
      "metadata": {
        "id": "2hPyCR2b2jB9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"learning\"></a>\n",
        "# Learning\n",
        "\n",
        "\n",
        "Remember: we need all of the following to train a ML model:\n",
        "\n",
        "- **Architecture**\n",
        "- **Loss**\n",
        "- **Optimizer**"
      ],
      "metadata": {
        "id": "Dqzw9nea1xVU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL1GBtviBVfY"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "## Inspiration: Hebbian learning\n",
        "\n",
        "[Hebbian learning rule](https://en.wikibooks.org/wiki/Artificial_Neural_Networks/Hebbian_Learning)\n",
        "- One of the oldest learning rules\n",
        "- If there is a high correlation between the outputs of two neurons at the two ends of a synapse (\"they fire together\") then the strength of the synapse should be increased (\"what fires together wires together\").\n",
        "\n",
        "$ w_{ij}[n+1]=w_{ij}[n]+\\eta x_{i}[n]x_{j}[n]$\n",
        "\n",
        "Where:\n",
        "\n",
        "- $n$ is the current time step.\n",
        "- $x_{i},x_{j}$ are the activations of the two neurons\n",
        "- $w$ is the strength of the synapse (later: \"weight\")\n",
        "- $\\eta$ is the learning rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU335vTrBVfZ"
      },
      "source": [
        "## The perceptron algorithm\n",
        "\n",
        "1. for all $d\\in 1..D$: $w_d \\leftarrow 0$ (initialize weights)\n",
        "2. $b \\leftarrow 0$ (initialize bias)\n",
        "3. $\\mathit{EpochCount}$ times: for all $(\\mathbf{x}, y)$ training examples\n",
        "   - Calculate the $a= \\mathbf w \\mathbf x + b$ activation\n",
        "   - If $ya \\leq 0$ (wrong or 0 prediction):\n",
        "       - $\\mathbf{w} \\leftarrow \\mathbf{w} + y\\mathbf{x}$\n",
        "       - $b \\leftarrow b + y$\n",
        "       \n",
        "(In more complex formulations there is also a learning rate parameter (most frequently signified by $\\eta$). Using this parameter the learning step would be:\n",
        "\n",
        "- $\\mathbf{w} \\leftarrow \\mathbf{w} + \\eta y\\mathbf{x}$\n",
        "- $b \\leftarrow b$ + $\\eta y$\n",
        "\n",
        "accordingly, the above simpler but perfectly functional(!) version uses a learning rate  $\\eta=1$.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixt483z_BVfa"
      },
      "source": [
        "### Why is this a useful update rule?\n",
        "\n",
        "Later we will see that the algorithm is guaranteed to a find a separator if the data set is separable. Regardless, it is simple to see that the update step changes the perceptron's output on the incorrectly classified example in the right direction, since the difference between the outputs before and after update:\n",
        "\n",
        "$$[(\\mathbf w + y\\mathbf x)\\mathbf x + b + y] - [\\mathbf w x + b] = y\\mathbf x^2 + y = y (\\mathbf x^2 + 1)$$\n",
        "\n",
        "that is, the output increases at least by 1 if the misclassified example was positive and decreases at least by 1 if it was negative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fvz23WJtPC9"
      },
      "source": [
        "   \n",
        "##  Complexity contrast with other learning algorithms\n",
        "\n",
        "### Perceptron algorithm\n",
        "\n",
        "Update was possible simply by rotating potentiometers (in the case of binary vectors by a single step forward or backward).\n",
        "#### vs, for instance, Newton's method\n",
        "\n",
        "Other methods for reducing the error rate can be way more complex. For instance, Newton's method, which approximates the minimum of the error function by using Newton's method to find its critical point:\n",
        "\n",
        "<a href=\"https://www.researchgate.net/profile/Daniel_Marcsa2/publication/266091369/figure/fig5/AS:476476194725892@1490612185738/The-geometrical-construction-of-Newton-Raphson-method.png\"><img src=\"https://drive.google.com/uc?export=view&id=1CRdZS-0tQuE3SEo7Yn5oeeX6IJluShYx\" width=40%></a>\n",
        "\n",
        "In the (typical) multidimensional case,\n",
        "\n",
        "- this requires the computation of the Hessian matrix, which consists of all second order partial derivatives\n",
        "- moreover, the Hessian needs to be inverted\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## EpochCount and order of processing\n",
        "\n",
        "- If the order of training examples is wrong then the perceptron learns only from a few examples\n",
        "- The order is so significant that a random shuffle of the original training data typically results in a 20% faster convergence."
      ],
      "metadata": {
        "id": "QisbllviE-_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Geometrical interpretation\n",
        "\n",
        "The **decision boundary** of a perceptron with $\\mathbf w$ weights and  $b$ bias is the set of possible inputs for which the activation is 0, that is, the set\n",
        "\n",
        "$$\\left\\{\\mathbf x : \\sum_{d=1}^D w_d x_d + b = 0\\right\\} = \\{\\mathbf x: \\mathbf w \\mathbf x + b = 0 \\}$$\n",
        "\n",
        "If $b = 0$ then the decision boundary is $\\{\\mathbf x: \\mathbf w \\mathbf x = 0 \\}$, which is the set of vectors that are perpendicular to $\\mathbf  w$, therefore the boundary is a  *hyperplane* which is perpendicular to  $\\mathbf w$ and crosses the $\\mathbf 0$ vector.\n",
        "\n",
        "<a href=\"https://ds055uzetaobb.cloudfront.net/image_optimizer/947723b3ba09371025dac3dab038f6b79a9ea2d3.png\"><img src=\"https://drive.google.com/uc?export=view&id=1hC2kVGM-yuYOw5PNW7mH4GyPRIE32sMC\"  height=\"400\"></a>\n"
      ],
      "metadata": {
        "id": "EQpnB43UQpU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In addition, if $\\mathbf w$ is a unit vector (we can assume that, since the decision boundary is determined solely by its direction), then the $\\mathbf w \\mathbf x$ activation will simply be the _signed projection_ of $\\mathbf x$  to $\\mathbf w$. On one side of the hyper plane the projection will be positive while on the other side negative, so the plane _separates_ the inputs which are predicted to be positive and negative.\n",
        "\n",
        "<a href=\"http://www.cs.cornell.edu/courses/cs4780/2015fa/web/lecturenotes/images/perceptron/perceptron_img1.png\"><img src=\"https://drive.google.com/uc?export=view&id=1Bc0zOu1qD6c5Gey8hnjaO3gHRhQ2VRFc\"  height=\"400\" ></a>\n",
        "\n",
        "The role of the $b$ bias is to *move* to separator hyperplane in parallel with  $\\mathbf w$ by exactly  $-b$ units.\n"
      ],
      "metadata": {
        "id": "kdCrCPTKQsO-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "FQC_X3Zdk0gk"
      },
      "source": [
        "\n",
        "## The hypercone of the good solutions\n",
        "\n",
        "<a href=\"http://drive.google.com/uc?export=view&id=1KIZ9QUaLL2SisNrzwegoa9WA5B2e31IL\"><img src=\"https://drive.google.com/uc?export=view&id=1HVtk-4g5BSegzt3AqFKMHrB8vwjFaA0t\" height=\"400\"></a>\n",
        "\n",
        "(Source: Hinton - Neural networks for machine learning)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Margin\n",
        "\n",
        "If the positive and negative examples of a $\\mathbf D$ data set are separated by the  hyperplane determined by a $\\mathbf w$ unit weight vector and $b$ bias then the minimum of the activations on $\\mathbf D$ is the separator's _margin_:\n",
        "\n",
        "$$\\mathrm{Margin}(\\mathbf D, \\mathbf w, b) = \\min_{(\\mathbf x, y) \\in \\mathbf D} y(\\mathbf w \\mathbf x + b)$$\n",
        "\n",
        "This is simply the minimum of the distances from the separator hyperplane. The margin of a data set can also be defined, this is the largest possible margin:\n",
        "\n",
        "$$\\mathrm{Margin}(\\mathbf D) = \\sup_{\\mathbf w, b}\\mathrm{Margin}(\\mathbf D, \\mathbf w, b)$$\n"
      ],
      "metadata": {
        "id": "MVXcfB2MQylt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "Fwee-aijbDhS"
      },
      "source": [
        "##  Convergence theorem\n",
        "Let's assume that for a $\\mathbf D$ data set in which $\\forall \\mathbf x_i: \\|\\mathbf x_i\\|\\leq 1$ there exists a $\\mathbf{w^*}$ optimal separator with the maximal $\\gamma$ margin, and the algorithm is performed with the a $\\mathbf w_0,...,\\mathbf w_i,\\dots$ update steps (for simplicity we assume that the bias is $0$ and the $\\mathbf w^*$ is chosen to be a unit vector -- none of these assumptions is essential for the result). In that case the algorithm finds a separator in a finite $k$ number of update steps, and, moreover, $k$ is guaranteed  to satisfy\n",
        "\n",
        "$$ k \\leq \\frac{1}{\\gamma^2}$$\n",
        "\n",
        "The key idea is to prove that the angle between  $\\mathbf {w}^*$ and $\\mathbf {w}_i$ decreases to the degree needed for the linear separation in a finite number of update steps.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJQ8iCqRtDkn"
      },
      "source": [
        "## Advantages and disadvantages of perceptron algorithm\n",
        "__Advantages__:\n",
        "- **online** --  processes one example at a time and possibly improves the model on the basis of this example. $\\Rightarrow$ Capable of continuously processing new incoming examples.\n",
        "- **fast** and simple\n",
        "- **convergence theorem**\n",
        "\n",
        "__Disadvantages__\n",
        "- In contrast to SVM, there is **no guarantee** that the resulting separator is **optimal**.\n",
        "- **Error-driven**: it can change a 99.99% precision model because of a single error\n",
        "- Convergence is **guaranteed only when there does exist a separator**! And that is not always the case..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28clyyLVtPDB"
      },
      "source": [
        "<a id=\"advancedperceptrons\"></a>\n",
        "# Advanced perceptrons\n",
        "\n",
        "##  The problem\n",
        "\n",
        "**Later** examples have **too large influence** on the learned weights -- a last update can change a weigth vector that worked well for all other examples (!).\n",
        "\n",
        "## Solutions\n",
        "\n",
        "### Voting\n",
        "\n",
        "The weights and bias are stored at every update, together with number of correct predictions since the last update. The learning process is unchanged, but in the prediction stage the system generates a prediction with all stored weights + bias values and the result is computed as the weighted sum of all of these predictions,  where the weights are the stored \"survival times\". Problem: Requires a huge amount of memory.\n",
        "\n",
        "### Averaged perceptron\n",
        "\n",
        "Similar, but more practical alternative: prediction is performed with the weighted average of the weights and biases that were generated during the learning process -- weights are, again, the \"survival times\".  In contrast to voting, here it is enough to maintain a rolling weighted average during the learning phase, so the additional memory consumption is negligible.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### example with just one weight to show that keeping rolling weighted averaging is enough:\n",
        "\n",
        "a = [1, -1, 2]      # weight of perceptrons\n",
        "b = [10, 5, 100]    # survival times (weights of the weights)\n",
        "\n",
        "c = [a[i]*b[i] for i in range(len(a))]  # pointwise multiplication\n",
        "wa1 = sum(c)/len(c)     # mean\n",
        "print(wa1, \"\\t= t(i) weighted average of weights\" )\n",
        "\n",
        "a2 = a + [3]        # a new perceptron weight\n",
        "b2 = b + [200]      # its survival time\n",
        "\n",
        "c2 = [a2[i]*b2[i] for i in range(len(a2))]\n",
        "wa2 = sum(c2)/len(c2)\n",
        "print(wa2, \"\\t= t(i+1) weighted average of weights using the stored weights and survival times\")\n",
        "\n",
        "wa2b = (wa1*(len(c2)-1) + (3*200))/len(c2)\n",
        "print(wa2b, \"\\t= t(i+1) weighted average of weights using previous weighted average of weights\")\n"
      ],
      "metadata": {
        "id": "arK8HpWxUIOz",
        "outputId": "8ed8495f-ed5f-42be-ed56-c1e41091edf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68.33333333333333 \t= t(i) weighted average of weights\n",
            "201.25 \t= t(i+1) weighted average of weights using the stored weights and survival times\n",
            "201.25 \t= t(i+1) weighted average of weights using previous weighted average of weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Limitations\n"
      ],
      "metadata": {
        "id": "E5g401JjSdfh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Minsky & Papert (1969): \"Perceptrons\"\n",
        "\n",
        "<a href=\"http://slideplayer.com/slide/775779/3/images/41/Minsky+&+Papert+(1969).jpg\"><img src =\"https://drive.google.com/uc?export=view&id=15clKwCvInuqSkbhH_f5GYhVphbtTBPqK\" width=600 heigth=600></a>\n"
      ],
      "metadata": {
        "id": "lBEd55S0SeVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### A very general perceptron definition\n",
        "multiple layers and nonlinearity are possible\n",
        "\n",
        "<a href=\"http://drive.google.com/uc?export=view&id=1ipkPyUFpS8bfTrXNIy6CqMOOAzm14Z9j\"><img src=\"https://drive.google.com/uc?export=view&id=1y9a4JaeJoTbf6v6IMNQx8e7c1D1mdHlv\" width=600 heigth=600></a>\n"
      ],
      "metadata": {
        "id": "9vYxeE8ZShth"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDwOqt297dRR"
      },
      "source": [
        "\n",
        "#### Criticism\n",
        "\n",
        "> Perceptrons have been widely publicized as \"pattern recognition\" or \"learning\" machines and as such have been discussed in a large number of books, journal articles, and voluminous \"reports.\" Most of this writing (some exceptions are mentioned in our bibliography) is without scientific value and we will not usually refer by name to the works we criticize. The sciences of computation and cybernetics began, and it seems quite rightly so, with a certain flourish of romanticism. They were laden with attractive and exciting new ideas which have already\n",
        "borne rich fruit. Heavy demands of rigor and caution could have held this development to a much slower pace; only the future could tell which directions were to be the best.\n",
        "\n",
        "##### \"The Seductive Powers of Perceptrons\"\n",
        "\n",
        "> Thus \"programming\" takes on a pleasingly homogeneous form. Moreover since \"programs\" are representable in a\n",
        "[multi]-dimensional space, they inherit a metric which makes it easy to imagine a kind of automatic programming which people have been tempted to call learning', by attaching feedback devices to the parameter controls they propose to \"program\" the machine by providing it with a sequence of input patterns and an \"error signal\" which will cause the coefficients to change in the right direction when the machine makes an inappropriate decision.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Goal: precise theory + what can they be used for?\n",
        "- Perceptrons are \"**massively parallel**\" machines -- these architectures were not so well understood as the classic sequential ones.\n",
        "- Although they write about **multilayer perceptrons** too, their most important _theorems_ concern **single layer linear perceptrons**.\n",
        "- Focus: perceptrons as **visual pattern** recognizers (this was their main application area at the time).\n",
        "- **Negative results**: some predicates, e.g., parity, connectedness etc. cannot be represented by certain types of perceptrons.  Their most well known result of this type is the XOR operation.\n"
      ],
      "metadata": {
        "id": "SjcYBfpgFNA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## XOR Problem\n",
        "- It was important to model logical operators\n",
        "- \"Feeding\" 0,1 input the output should be the corresponding operation result\n",
        "- A perceptron can model a logical operation only if it is linearly separable\n"
      ],
      "metadata": {
        "id": "NfEoxYUtSnyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### The truth table of XOR\n",
        "\n",
        "\n",
        "\n",
        "$\\Large x_1$ | $\\Large x_2$ | $\\Large x_1 \\textbf{XOR } x_2$   \n",
        ":---: | :---: | :---:\n",
        "$\\Large 0$ | $\\Large 0$ | $\\Large 0$\n",
        "$\\Large 0$ | $\\Large 1$ | $\\Large 1$\n",
        "$\\Large 1$ | $\\Large 0$ | $\\Large 1$\n",
        "$\\Large 1$ | $\\Large 1$ | $\\Large 0$\n"
      ],
      "metadata": {
        "id": "ibUx44hFSpBM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem\n",
        "\n",
        "<a href=\"http://drive.google.com/uc?export=view&id=1m59mOWDu7yShgMpSgw2yC8YDVzi1-fzs\"><img src=\"https://drive.google.com/uc?export=view&id=1Ci6_UtG_Lr2UnwQQv6r86382TnSfGTf5\" style=\"width: 80%;\"></a>\n"
      ],
      "metadata": {
        "id": "OVAK1cNXFOmf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### The XOR proof\n",
        "Let us assume, toward a contradiction, that a $w_1,w_2, b$ perceptron computes XOR. Then\n",
        "\n",
        "1. $w_1 + b > 0$\n",
        "2. $w_2 + b > 0$\n",
        "3. $w_1 + w_2 + b \\leq 0$\n",
        "4. $b \\leq 0 $\n",
        "\n",
        "But adding (1) and (2) we have: $w_1 + w_2 + 2b > 0$\n",
        "\n",
        "And adding (3) and (4) we get: $w_1 + w_2 + 2b \\leq 0$, which is a contradiction.\n",
        "\n"
      ],
      "metadata": {
        "id": "igYinWLQSujx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# History: AI winter\n"
      ],
      "metadata": {
        "id": "RNMOTudjhnYp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AI summers and winters\n",
        "\n",
        "Worth reading: [Wikipedia - AI winter](https://en.wikipedia.org/wiki/AI_winter)\n",
        "\n",
        "<a href=\"https://image.slidesharecdn.com/20170311aipresentationtorecord-170329202319/95/a-primer-on-artificial-intelligence-ai-and-machine-learning-ml-8-638.jpg?cb=1490819184\"><img src=\"https://drive.google.com/uc?export=view&id=1Xu3eazocOHN0m34Acfx3CwjIzy9hkNGV\"></a>\n",
        "\n",
        "\"The AI industry, which many market researchers had projected would reach 4 billion USD in annual sales by now, remains nascent. Generous estimates of the market today are closer to 600 million USD. After swallowing up hundreds of millions of dollars in venture capital‚Ä¶hundreds of AI start-ups have yielded only a few profitable public companies. (Wall Street Journal, ‚ÄúBright Outlook for Artificial Intelligence Yields to Slow Growth and Big Cutbacks‚Äù, 7/5/1990.)\"\n",
        "\n",
        "[Source](http://reactionwheel.net/2015/01/80s-vc.html)\n",
        "\n",
        "\"Expert systems: Human Issues MIT Press,1990 Despite almost two decades of intensive R&D, there are still relatively few expert systems in working practice. If a computer is providing ‚Äúadvice\" how far can that advice be trusted? Who is responsible if it turns out to be wrong? Do the decisions of human experts depend on implicit knowledge that cannot be captured ... Essays in this book consider case studies of a medical expert system and management of child abouse cases, issues in designing expert systems for business... a systemic approach to organizational... and responsibility issues. The editors conclude with a brief discussion of integrating expert systems with other computer systems... legal implications, the possibilities of joint cognitive systems (seeking to supplement human supplement rather than replace them), and worries about deskilling ALSO SEE: Bright Outlook for Artificial Intelligence (Wall Street Journal. 5 July 1990) on ** employment cuts in the AI industry ranging from 50-90%.** The biggest AI market is for expert systems; AI is also used in computerized vision system and speech recognition system.\"  - Future Survey Annual 1992"
      ],
      "metadata": {
        "id": "-yuLiMFPgqLp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Always starting from scratch?!\n",
        "\n",
        "<a href=\"https://image.slidesharecdn.com/tekesfuturewatchchinamodule26ai-170825094305/95/future-watch-chinas-digital-landscape-and-rising-disruptors-module-26-artificial-intelligence-7-638.jpg?cb=1503654352\"><img src=\"https://drive.google.com/uc?export=view&id=1XAKZjuotysr88CcuQQvuULTB_l19bljY\"></a>\n"
      ],
      "metadata": {
        "id": "3A1zuj4xg07h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "And:\n",
        "\n",
        "### Automatic speech recognition results:\n",
        "<a href=\"https://cdn-images-1.medium.com/max/1600/1*eRD00-2GaCjz97AfhHlQoQ.png\"><img src=\"https://drive.google.com/uc?export=view&id=1sFeopvD9X7N7jvpF8camcPIpOhu--C1z\"></a>\n"
      ],
      "metadata": {
        "id": "RZPlagE2g_IX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Where can I follow the developments?\n",
        "\n",
        "Nice summary page:\n",
        "\n",
        "### **[Electronic Frontier Foundation - AI progress metrics](https://www.eff.org/ai/metrics)**\n",
        "\n",
        "<a href=\"http://drive.google.com/uc?export=view&id=1pelDZmTING7dbgqborEW16Pr0PV7y0-_\"><img src=\"https://drive.google.com/uc?export=view&id=16BZMRiYDsz_Brvyz430nehkOoCkCMLd4\"></a>\n",
        "\n",
        "Or more up to date:\n",
        "\n",
        "[Papers with code](https://paperswithcode.com/state-of-the-art)\n"
      ],
      "metadata": {
        "id": "1s2uAkSAhBNP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## \"The resistance\"\n",
        "\n",
        "During the AI winters the mainstream of scientific community - in image recognition, speech, language and in other AI fields - was strongly against the usage of neural networks, since they regarded it as a \"dead paradigm\". But the history of AI as a scientific field teaches us not to disregard some old ideas, since they can easily arise in new forms again (like genetic algorithms entering mainstream again in [this](https://www.technologyreview.com/s/611568/evolutionary-algorithm-outperforms-deep-learning-machines-at-video-games/) case).\n",
        "\n",
        "The \"resistance\" during the neural network winter is well represented by the work of [**Geoffrey Hinton**](https://en.wikipedia.org/wiki/Geoffrey_Hinton), who was working on new learning algorithms for neural models in the mid 80s, especially backpropagation, thus securing his name as [\"the godfather of deep learning\"](https://www.youtube.com/watch?v=uAu3jQWaN6E) - and a media celebrity and \"face\" for the movement.)\n",
        "\n",
        "<a href=\"https://images.thestar.com/C_Dnyhg8tb3tVXiGtq93vee9oJM=/1200x799/smart/filters:cb(1524397170509)/https://www.thestar.com/content/dam/thestar/news/world/2015/04/17/how-a-toronto-professors-research-revolutionized-artificial-intelligence/geoffrey-hinton-3.jpg\"><img src=\"https://drive.google.com/uc?export=view&id=1fyGu0l-IRygH3kZI29obj_QICJrDTBZs\" width=600 heigth=600></a>\n"
      ],
      "metadata": {
        "id": "MeZrfDePhEX5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mxx1lK_Vgc4"
      },
      "source": [
        "\n",
        "Others also followed. (Except Schmidhuber, who claims: he started the whole thing on his own. :-)\n",
        "\n",
        "<a href=\"https://i.imgur.com/lq1LDVO.png\"><img src=\"https://drive.google.com/uc?export=view&id=1meHVdAid2oN1UPEHuUjXRG5NIrAYwGCm\" height=\"400\" width=\"400\" align=\"left\"></a>\n",
        "\n",
        "\n",
        "### J√ºrgen Schmidhuber,\n",
        "### Joshua Bengio,\n",
        "### Geoffrey Hinton,\n",
        "### Yann LeCun,\n",
        "### Andrew Ng"
      ]
    }
  ]
}